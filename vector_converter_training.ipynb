{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65b61a77-ace2-4e13-a51e-b7f87babbb45",
   "metadata": {},
   "source": [
    "# Vector Converter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc86a5b-110b-4e8a-b79e-2547ec12020a",
   "metadata": {},
   "source": [
    "## Step 1. Import needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c607b3b6-b197-4c8e-9956-b51d99887e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Import pyplot from matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import TensorFlow & Keras \n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing import image as image_preprocessing\n",
    "import tensorflow.keras.backend as tf_backend \n",
    "tf_backend.set_image_data_format('channels_last')\n",
    "\n",
    "# Import all other needed packages\n",
    "import numpy as np\n",
    "import csv\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d11dd4b-850b-41b1-9376-379787551392",
   "metadata": {},
   "source": [
    "## Step 2. Generate train & test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdaa801f-d93d-4468-a04e-1012c892576f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-15 00:50:08.244882: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-15 00:50:08.245929: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "# Forming feature vectors dictionary\n",
    "feature_vectors_dictionary = {}\n",
    "\n",
    "with open('./output/keras_facenet_feature_vectors.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    for i, row in enumerate(reader):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        \n",
    "        person_id = int(float(row[0]))\n",
    "        feature_vector = np.array(row[2:])\n",
    "        feature_vector = feature_vector.astype(np.float)\n",
    "        \n",
    "        if person_id not in feature_vectors_dictionary:\n",
    "            feature_vectors_dictionary[person_id] = [feature_vector]\n",
    "            continue\n",
    "            \n",
    "        feature_vectors_dictionary[person_id].append(feature_vector)\n",
    "\n",
    "dictionary_values = list(feature_vectors_dictionary.values()) \n",
    "        \n",
    "# Finding minimal array size\n",
    "min_array_length = int(1e10)\n",
    "for value in dictionary_values:\n",
    "    min_array_length = min(min_array_length, len(value))\n",
    "\n",
    "# Forming tensorflow and numpy arrays\n",
    "feature_vector_batches_np = []\n",
    "feature_vector_batches_tf = []\n",
    "labels = []\n",
    "\n",
    "for key in feature_vectors_dictionary:\n",
    "    value = feature_vectors_dictionary[key]\n",
    "    value_np = np.array(value[:min_array_length])\n",
    "    labels.extend([key] * min_array_length)\n",
    "    feature_vector_batches_np.extend(value_np)\n",
    "    feature_vector_batches_tf.extend(tf.convert_to_tensor(value_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af8ccf93-2851-407b-9e42-a40b0657d47f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor, Negative, and Positive labels are 72, 123, and 72\n",
      "Distance between anchor and negative is 263.00629066112015\n",
      "Distance between anchor and positive is 54.884614391208856\n",
      "Total dataset length: 5512\n",
      "Length of a train dataset: 4409\n",
      "Length of a test dataset: 1103\n"
     ]
    }
   ],
   "source": [
    "# Shuffle two lists\n",
    "temp = list(zip(feature_vector_batches_np, feature_vector_batches_tf, labels))\n",
    "random.shuffle(temp)\n",
    "temp_batches_np, temp_batches_tf, temp_labels = zip(*temp)\n",
    "feature_vector_batches_np, feature_vector_batches_tf, labels = list(temp_batches_np), list(temp_batches_tf), list(temp_labels)\n",
    "\n",
    "feature_vector_batches_tf = tf.stack(feature_vector_batches_tf)\n",
    "\n",
    "# Test shuffling\n",
    "def euclidean_distance(f1, f2):\n",
    "    return tf.reduce_sum(tf.square(f1-f2), axis=0)\n",
    "\n",
    "anchor, anchor_label = feature_vector_batches_tf[0], labels[0]\n",
    "\n",
    "positive_id, negative_id = -1, -1 \n",
    "for i, vector in enumerate(feature_vector_batches_np):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    if positive_id >= 0 and negative_id >= 0:\n",
    "        break\n",
    "    if labels[i] != anchor_label and negative_id == -1:\n",
    "        negative_id = i\n",
    "    if labels[i] == anchor_label and positive_id == -1:\n",
    "        positive_id = i\n",
    "\n",
    "negative, positive = feature_vector_batches_tf[negative_id], feature_vector_batches_tf[positive_id]\n",
    "negative_label, positive_label = labels[negative_id], labels[positive_id]\n",
    "        \n",
    "print('Anchor, Negative, and Positive labels are {}, {}, and {}'.format(anchor_label, negative_label, positive_label))\n",
    "print('Distance between anchor and negative is {}'.format(euclidean_distance(anchor, negative)))\n",
    "print('Distance between anchor and positive is {}'.format(euclidean_distance(anchor, positive)))    \n",
    "\n",
    "# Splitting into training and test sets\n",
    "total_dataset_length = len(labels)\n",
    "test_proportion = 0.8\n",
    "train_length = int(test_proportion * total_dataset_length)\n",
    "\n",
    "X_train = feature_vector_batches_tf[:train_length]\n",
    "Y_train = labels[:train_length]\n",
    "\n",
    "X_test = feature_vector_batches_tf[train_length:]\n",
    "Y_test = labels[train_length:]\n",
    "\n",
    "print('Total dataset length: {}'.format(total_dataset_length))\n",
    "print('Length of a train dataset: {}'.format(len(X_train)))\n",
    "print('Length of a test dataset: {}'.format(len(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847e49eb-3b65-4ab0-93bd-a2b723d981fc",
   "metadata": {},
   "source": [
    "## Step 3. Define distance function\n",
    "\n",
    "Suppose we have two feature vectors $\\mathbf{f}$ and $\\mathbf{g}$ and suppose we have a model $\\mu: \\mathbb{R}^N \\to \\mathbb{R}^N$\n",
    "\n",
    "Since we need a function $\\psi: \\mathbb{R}^N \\to \\Sigma^N$ we define it as follows:\n",
    "$$\n",
    "\\psi(\\mathbf{f}) = \\begin{cases} 1, \\mu(\\mathbf{f}) \\geq 0 \\\\ 0, \\mu(\\mathbf{f}) < 0 \\end{cases}\n",
    "$$\n",
    "\n",
    "Therefore, our binary distance has a form:\n",
    "$$\n",
    "\\delta(\\mathbf{f}, \\mathbf{g}) = \\frac{1}{N}\\sum_{k=1}^N |\\psi(\\mathbf{f})_k - \\psi(\\mathbf{g})_k|\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3524c9ce-2415-451c-b25c-13e12f524c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.25, shape=(), dtype=float32)\n",
      "tf.Tensor([1. 1. 0. 1. 0.], shape=(5,), dtype=float32)\n",
      "tf.Tensor(0.25, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def binary_distance(s1, s2):\n",
    "    return tf.reduce_mean(tf.abs(s1-s2),axis=0)\n",
    "\n",
    "# Check binary distance formula\n",
    "s1 = tf.constant([0.0, 0.0, 1.0, 1.0])\n",
    "s2 = tf.constant([0.0, 0.0, 1.0, 0.0])\n",
    "print(binary_distance(s1, s2))\n",
    "\n",
    "def convert_to_binary_string(f):\n",
    "    return tf.where(tf.less(f, 0.0), 0.0, 1.0)\n",
    "\n",
    "f = tf.constant([1.3, 2.5, -2.3, 0.2, -0.3])\n",
    "print(convert_to_binary_string(f))\n",
    "\n",
    "def binary_distance_vectors(f1, f2):\n",
    "    return binary_distance(convert_to_binary_string(f1), convert_to_binary_string(f2))\n",
    "\n",
    "f1 = tf.constant([-0.2, -0.3, 0.4, 0.5])\n",
    "f2 = tf.constant([-0.6, -0.7, 0.8, -0.9])\n",
    "print(binary_distance_vectors(f1, f2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dfa1d7-abb6-406a-aa8d-23e17cf3d5c0",
   "metadata": {},
   "source": [
    "## Step 4. Creating functions to create batches & triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "379b14b0-4d60-482b-a014-94714987a946",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batch(batch_size=256, split = \"train\"):\n",
    "    x_anchors = np.zeros((batch_size, 128))\n",
    "    x_positives = np.zeros((batch_size, 128))\n",
    "    x_negatives = np.zeros((batch_size, 128))\n",
    "    \n",
    "    if split == \"train\":\n",
    "        data = X_train\n",
    "        data_y = Y_train\n",
    "    elif split == \"test\":\n",
    "        data = X_test\n",
    "        data_y = Y_test\n",
    "    \n",
    "    for i in range(0, batch_size):\n",
    "        # We need to find an anchor, a positive example and a negative example\n",
    "        random_index = random.randint(0, data.shape[0] - 1)\n",
    "        x_anchor = data[random_index]\n",
    "        y = data_y[random_index]\n",
    "        \n",
    "        indices_for_pos = [index for index in data_y if index == y]\n",
    "        indices_for_neg = [index for index in data_y if index != y]\n",
    "        \n",
    "        x_positive = data[indices_for_pos[random.randint(0, len(indices_for_pos) - 1)]]\n",
    "        x_negative = data[indices_for_neg[random.randint(0, len(indices_for_neg) - 1)]]\n",
    "        \n",
    "        x_anchors[i] = x_anchor\n",
    "        x_positives[i] = x_positive\n",
    "        x_negatives[i] = x_negative\n",
    "        \n",
    "    return [x_anchors, x_positives, x_negatives]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea6c2ad5-80a5-4d47-8522-e7f9ca03abb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hard_batch(batch_size, num_hard, split=\"train\"):\n",
    "    x_anchors = np.zeros((batch_size, 128))\n",
    "    x_positives = np.zeros((batch_size, 128))\n",
    "    x_negatives = np.zeros((batch_size, 128))\n",
    "    \n",
    "    if split == \"train\":\n",
    "        data = X_train\n",
    "        data_y = Y_train\n",
    "    elif split == \"test\":\n",
    "        data = X_test\n",
    "        data_y = Y_test\n",
    "    \n",
    "    # Generate num_hard number of hard examples:\n",
    "    hard_batches = [] \n",
    "    batch_losses = []\n",
    "    rand_batches = []\n",
    "    \n",
    "    # Get some random batches\n",
    "    for i in range(0, batch_size):\n",
    "        hard_batches.append(create_batch(1, split))\n",
    "        \n",
    "        A_emb = embedding_model.predict(hard_batches[i][0])\n",
    "        P_emb = embedding_model.predict(hard_batches[i][1])\n",
    "        N_emb = embedding_model.predict(hard_batches[i][2])\n",
    "        \n",
    "        # Compute d(A, P) - d(A, N) for each selected batch\n",
    "        batch_losses.append(binary_distance_vectors(A_emb, P_emb)-binary_distance_vectors(A_emb,P_emb))\n",
    "    \n",
    "    # Sort batch_loss by distance, highest first, and keep num_hard of them\n",
    "    hard_batch_selections = [x for _, x in sorted(zip(batch_losses,hard_batches), key=lambda x: x[0])]\n",
    "    hard_batches = hard_batch_selections[:num_hard]\n",
    "    \n",
    "    # Get batch_size - num_hard number of random examples\n",
    "    num_rand = batch_size - num_hard\n",
    "    for i in range(0, num_rand):\n",
    "        rand_batch = create_batch(1, split)\n",
    "        rand_batches.append(rand_batch)\n",
    "    \n",
    "    selections = hard_batches + rand_batches\n",
    "    \n",
    "    for i in range(0, len(selections)):\n",
    "        x_anchors[i] = selections[i][0]\n",
    "        x_positives[i] = selections[i][1]\n",
    "        x_negatives[i] = selections[i][2]\n",
    "        \n",
    "    return [x_anchors, x_positives, x_negatives]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b132038b-296c-48ff-8ed3-80d33c124873",
   "metadata": {},
   "source": [
    "## Step 5. Creating SNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94851b2e-34df-4d67-b757-210cdefff6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model would consist of 3 dense layers of the same length as of feature vectors\n",
    "def init_embedding_model():\n",
    "    embedding_model = keras.Sequential([\n",
    "        layers.Dense(128, input_shape=(128,), activation=\"relu\", name=\"dense_layer_1\"),\n",
    "        layers.Dense(128, activation=\"relu\", name=\"dense_layer_2\"),\n",
    "        layers.Dense(128, name=\"dense_layer_3\"),\n",
    "    ])\n",
    "    \n",
    "    embedding_model.summary()\n",
    "    return embedding_model\n",
    "\n",
    "def init_snn(embedding_model):\n",
    "    input_anchor = layers.Input(shape=(128,))\n",
    "    input_positive = layers.Input(shape=(128,))\n",
    "    input_negative = layers.Input(shape=(128,))\n",
    "\n",
    "    embedding_anchor = embedding_model(input_anchor)\n",
    "    embedding_positive = embedding_model(input_positive)\n",
    "    embedding_negative = embedding_model(input_negative)\n",
    "\n",
    "    output = layers.concatenate([embedding_anchor, embedding_positive, embedding_negative], axis=1)\n",
    "    \n",
    "    siamese_net = keras.models.Model([input_anchor, input_positive, input_negative], output)\n",
    "    siamese_net.summary()\n",
    "    \n",
    "    return siamese_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5006b073-7578-4a21-abed-1a919551e014",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(y_true, y_pred):\n",
    "    anchor, positive, negative = y_pred[:,:emb_size], y_pred[:,emb_size:2*emb_size],y_pred[:,2*emb_size:]\n",
    "    positive_distance = binary_distance_vectors(anchor, positive)\n",
    "    negative_distance = binary_distance_vectors(anchor, negative)\n",
    "    return tf.maximum(positive_distance - negative_distance + alpha, 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e18d2fe3-cb88-477e-b0d2-d3c02fc47b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(batch_size=256, num_hard=50, split=\"train\"):\n",
    "    while True:\n",
    "        x = create_hard_batch(batch_size, num_hard, split)\n",
    "        y = np.zeros((batch_size, 3*emb_size))\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a29796-561f-44e8-b38e-50f207e30597",
   "metadata": {},
   "source": [
    "## Step 6. Setting up for training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7fe2f3d-7cec-45ff-96de-cbefeaeee123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embedding model... \n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_layer_1 (Dense)       (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_layer_2 (Dense)       (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_layer_3 (Dense)       (None, 128)               16512     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49,536\n",
      "Trainable params: 49,536\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Generating SNN... \n",
      "\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " sequential (Sequential)        (None, 128)          49536       ['input_1[0][0]',                \n",
      "                                                                  'input_2[0][0]',                \n",
      "                                                                  'input_3[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 384)          0           ['sequential[0][0]',             \n",
      "                                                                  'sequential[1][0]',             \n",
      "                                                                  'sequential[2][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 49,536\n",
      "Trainable params: 49,536\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Hyperparams\n",
    "batch_size = 256\n",
    "epochs = 10\n",
    "steps_per_epoch = int(X_train.shape[0]/batch_size)\n",
    "val_steps = int(X_test.shape[0]/batch_size)\n",
    "alpha = 0.3\n",
    "num_hard = int(batch_size * 0.5) # Number of semi-hard triplet examples in the batch\n",
    "lr = 0.00006\n",
    "optimiser = 'Adam'\n",
    "\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    # Create the embedding model\n",
    "    print(\"Generating embedding model... \\n\")\n",
    "    embedding_model = init_embedding_model()\n",
    "    \n",
    "    print(\"\\nGenerating SNN... \\n\")\n",
    "    # Create the SNN\n",
    "    siamese_net = init_snn(embedding_model)\n",
    "    # Compile the SNN\n",
    "    optimiser_obj = Adam(lr = lr)\n",
    "    siamese_net.compile(loss=triplet_loss, optimizer=optimiser_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae25bdf-1a85-4c86-add0-70b7feaa0123",
   "metadata": {},
   "source": [
    "## Step 7. Some random shit I do not understand for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eae52eae-0124-4bb9-aa37-02bc66b39c00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import math\n",
    "\n",
    "num_classes = len(np.unique(Y_train))\n",
    "\n",
    "def compute_dist(a,b):\n",
    "    return np.linalg.norm(a-b)\n",
    "\n",
    "def compute_probs(network,X,Y):\n",
    "    '''\n",
    "    Input\n",
    "        network : current NN to compute embeddings\n",
    "        X : tensor of shape (m,w,h,1) containing pics to evaluate\n",
    "        Y : tensor of shape (m,) containing true class\n",
    "        \n",
    "    Returns\n",
    "        probs : array of shape (m,m) containing distances\n",
    "    \n",
    "    '''\n",
    "    m = X.shape[0]\n",
    "    nbevaluation = int(m*(m-1)/2)\n",
    "    probs = np.zeros((nbevaluation))\n",
    "    y = np.zeros((nbevaluation))\n",
    "    \n",
    "    #Compute all embeddings for all imgs with current embedding network\n",
    "    embeddings = embedding_model.predict(X)\n",
    "    \n",
    "    k = 0\n",
    "    \n",
    "    # For each img in the evaluation set\n",
    "    for i in range(m):\n",
    "            # Against all other images\n",
    "            for j in range(i+1,m):\n",
    "                # compute the probability of being the right decision : it should be 1 for right class, 0 for all other classes\n",
    "                probs[k] = -compute_dist(embeddings[i,:],embeddings[j,:])\n",
    "                if (Y[i]==Y[j]):\n",
    "                    y[k] = 1\n",
    "                    #print(\"{3}:{0} vs {1} : \\t\\t\\t{2}\\tSAME\".format(i,j,probs[k],k, Y[i], Y[j]))\n",
    "                else:\n",
    "                    y[k] = 0\n",
    "                    #print(\"{3}:{0} vs {1} : {2}\\tDIFF\".format(i,j,probs[k],k, Y[i], Y[j]))\n",
    "                k += 1\n",
    "    return probs, y\n",
    "\n",
    "\n",
    "def compute_metrics(probs,yprobs):\n",
    "    '''\n",
    "    Returns\n",
    "        fpr : Increasing false positive rates such that element i is the false positive rate of predictions with score >= thresholds[i]\n",
    "        tpr : Increasing true positive rates such that element i is the true positive rate of predictions with score >= thresholds[i].\n",
    "        thresholds : Decreasing thresholds on the decision function used to compute fpr and tpr. thresholds[0] represents no instances being predicted and is arbitrarily set to max(y_score) + 1\n",
    "        auc : Area Under the ROC Curve metric\n",
    "    '''\n",
    "    # calculate AUC\n",
    "    auc = roc_auc_score(yprobs, probs)\n",
    "    # calculate roc curve\n",
    "    fpr, tpr, thresholds = roc_curve(yprobs, probs)\n",
    "    \n",
    "    return fpr, tpr, thresholds,auc\n",
    "\n",
    "def draw_roc(fpr, tpr,thresholds, auc):\n",
    "    #find threshold\n",
    "    targetfpr=1e-3\n",
    "    _, idx = find_nearest(fpr,targetfpr)\n",
    "    threshold = thresholds[idx]\n",
    "    recall = tpr[idx]\n",
    "    \n",
    "    \n",
    "    # plot no skill\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "    # plot the roc curve for the model\n",
    "    plt.plot(fpr, tpr, marker='.')\n",
    "    plt.title('AUC: {0:.3f}\\nSensitivity : {2:.1%} @FPR={1:.0e}\\nThreshold={3})'.format(auc,targetfpr,recall,abs(threshold) ))\n",
    "    # show the plot\n",
    "    plt.show()\n",
    "    \n",
    "def find_nearest(array,value):\n",
    "    idx = np.searchsorted(array, value, side=\"left\")\n",
    "    if idx > 0 and (idx == len(array) or math.fabs(value - array[idx-1]) < math.fabs(value - array[idx])):\n",
    "        return array[idx-1],idx-1\n",
    "    else:\n",
    "        return array[idx],idx\n",
    "    \n",
    "def draw_interdist(network, epochs):\n",
    "    interdist = compute_interdist(network)\n",
    "    \n",
    "    data = []\n",
    "    for i in range(num_classes):\n",
    "        data.append(np.delete(interdist[i,:],[i]))\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_title('Evaluating embeddings distance from each other after {0} epochs'.format(epochs))\n",
    "    ax.set_ylim([0,3])\n",
    "    plt.xlabel('Classes')\n",
    "    plt.ylabel('Distance')\n",
    "    ax.boxplot(data,showfliers=False,showbox=True)\n",
    "    locs, labels = plt.xticks()\n",
    "    plt.xticks(locs,np.arange(num_classes))\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def evaluate(embedding_model, epochs = 0):\n",
    "    probs,yprob = compute_probs(embedding_model, X_test[:500, :], Y_test[:500])\n",
    "    fpr, tpr, thresholds, auc = compute_metrics(probs,yprob)\n",
    "    draw_roc(fpr, tpr, thresholds, auc)\n",
    " \n",
    "evaluate(embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fe2e77f4-f927-4e33-a0df-3a98cbc860f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example triplet batch:\n",
      "Distance AP: tf.Tensor(0.5703125, shape=(), dtype=float32)\n",
      "Distance AN: tf.Tensor(0.5859375, shape=(), dtype=float32)\n",
      "Example semi-hard triplet batch:\n",
      "Distance AP: tf.Tensor(0.4453125, shape=(), dtype=float32)\n",
      "Distance AN: tf.Tensor(0.5390625, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "examples = create_batch(1)\n",
    "print(\"Example triplet batch:\")\n",
    "print(\"Distance AP:\", binary_distance_vectors(examples[0][0], examples[1][0]))\n",
    "print(\"Distance AN:\", binary_distance_vectors(examples[0][0], examples[2][0]))\n",
    "\n",
    "print(\"Example semi-hard triplet batch:\")\n",
    "# 1 example, containing 1 semi-hard\n",
    "ex_hard = create_hard_batch(1, 1, split=\"train\")\n",
    "print(\"Distance AP:\", binary_distance_vectors(ex_hard[0][0], ex_hard[1][0]))\n",
    "print(\"Distance AN:\", binary_distance_vectors(ex_hard[0][0], ex_hard[2][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d59eea-af69-492d-b29a-a18a9a67ed8c",
   "metadata": {},
   "source": [
    "## Step 8. Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dc91d56b-4ceb-4ed3-8cce-dfda1963d304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n",
      "WARNING:tensorflow:`batch_size` is no longer needed in the `TensorBoard` Callback and will be ignored in TensorFlow 2.0.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from tensorflow.keras.callbacks import Callback, CSVLogger, ModelCheckpoint\n",
    "# Set up logging directory\n",
    "## Use date-time as logdir name:\n",
    "#dt = datetime.now().strftime(\"%Y%m%dT%H%M\")\n",
    "#logdir = os.path.join(\"PATH/TO/LOG\",dt)\n",
    "\n",
    "## Use a custom non-dt name:\n",
    "name = \"snn-run\"\n",
    "logdir = os.path.join(\"./log\",name)\n",
    "\n",
    "if not os.path.exists(logdir):\n",
    "    os.mkdir(logdir)\n",
    "\n",
    "## Callbacks:\n",
    "# Create the TensorBoard callback\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir = logdir,\n",
    "    histogram_freq=0,\n",
    "    batch_size=batch_size,\n",
    "    write_graph=True,\n",
    "    write_grads=True, \n",
    "    write_images = True, \n",
    "    update_freq = 'epoch', \n",
    "    profile_batch=0\n",
    ")\n",
    "\n",
    "# Training logger\n",
    "csv_log = os.path.join(logdir, 'training.csv')\n",
    "csv_logger = CSVLogger(csv_log, separator=',', append=True)\n",
    "\n",
    "# Only save the best model weights based on the val_loss\n",
    "checkpoint = ModelCheckpoint(os.path.join(logdir, 'snn_model-{epoch:02d}-{val_loss:.2f}.h5'),\n",
    "                             monitor='val_loss', verbose=1,\n",
    "                             save_best_only=True, save_weights_only=True, \n",
    "                             mode='auto')\n",
    "\n",
    "# Save the embedding mode weights based on the main model's val loss\n",
    "# This is needed to reecreate the emebedding model should we wish to visualise\n",
    "# the latent space at the saved epoch\n",
    "class SaveEmbeddingModelWeights(Callback):\n",
    "    def __init__(self, filepath, monitor='val_loss', verbose=1):\n",
    "        super(Callback, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.verbose = verbose\n",
    "        self.best = np.Inf\n",
    "        self.filepath = filepath\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is None:\n",
    "            warnings.warn(\"SaveEmbeddingModelWeights requires %s available!\" % self.monitor, RuntimeWarning)\n",
    "\n",
    "        if current < self.best:\n",
    "            filepath = self.filepath.format(epoch=epoch + 1, **logs)\n",
    "            if self.verbose == 1:\n",
    "                print(\"Saving embedding model weights at %s\" % filepath)\n",
    "            embedding_model.save_weights(filepath, overwrite = True)\n",
    "            self.best = current\n",
    "            \n",
    "            # Delete the last best emb_model and snn_model\n",
    "            delete_older_model_files(filepath)\n",
    "\n",
    "# Save the embedding model weights if you save a new snn best model based on the model checkpoint above\n",
    "emb_weight_saver = SaveEmbeddingModelWeights(os.path.join(logdir, 'emb_model-{epoch:02d}.h5'))\n",
    "\n",
    "\n",
    "callbacks = [tensorboard, csv_logger, checkpoint, emb_weight_saver]\n",
    "\n",
    "\n",
    "# Save model configs to JSON\n",
    "model_json = siamese_net.to_json()\n",
    "with open(os.path.join(logdir, \"siamese_config.json\"), \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    json_file.close()\n",
    "    \n",
    "model_json = embedding_model.to_json()\n",
    "with open(os.path.join(logdir, \"embedding_config.json\"), \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    json_file.close()\n",
    "    \n",
    "\n",
    "hyperparams = {'batch_size' : batch_size,\n",
    "              'epochs' : epochs, \n",
    "               'steps_per_epoch' : steps_per_epoch, \n",
    "               'val_steps' : val_steps, \n",
    "               'alpha' : alpha, \n",
    "               'num_hard' : num_hard, \n",
    "               'optimiser' : optimiser,\n",
    "               'lr' : lr,\n",
    "               'emb_size' : 128\n",
    "              }\n",
    "\n",
    "\n",
    "with open(os.path.join(logdir, \"hyperparams.json\"), \"w\") as json_file:\n",
    "    json.dump(hyperparams, json_file)\n",
    "    \n",
    "# Set the model to TB\n",
    "tensorboard.set_model(siamese_net)\n",
    "\n",
    "def delete_older_model_files(filepath):\n",
    "    \n",
    "    model_dir = filepath.split(\"emb_model\")[0]\n",
    "    \n",
    "    # Get model files\n",
    "    model_files = os.listdir(model_dir)\n",
    "    # Get only the emb_model files\n",
    "    emb_model_files = [file for file in model_files if \"emb_model\" in file]\n",
    "    # Get the epoch nums of the emb_model_files\n",
    "    emb_model_files_epoch_nums = [file.split(\"-\")[1].split(\".h5\")[0] for file in emb_model_files]\n",
    "\n",
    "    # Find all the snn model files\n",
    "    snn_model_files = [file for file in model_files if \"snn_model\" in file]\n",
    "\n",
    "    # Sort, get highest epoch num\n",
    "    emb_model_files_epoch_nums.sort()\n",
    "    highest_epoch_num = emb_model_files_epoch_nums[-1]\n",
    "\n",
    "    # Filter the emb_model and snn_model file lists to remove the highest epoch number ones\n",
    "    emb_model_files_without_highest = [file for file in emb_model_files if highest_epoch_num not in file]\n",
    "    snn_model_files_without_highest = [file for file in snn_model_files if highest_epoch_num not in file]\n",
    "\n",
    "    # Delete the non-highest model files from the subdir\n",
    "    if len(emb_model_files_without_highest) != 0:\n",
    "        print(\"Deleting previous best model file:\", emb_model_files_without_highest)\n",
    "        for model_file_list in [emb_model_files_without_highest, snn_model_files_without_highest]:\n",
    "            for file in model_file_list:\n",
    "                os.remove(os.path.join(model_dir, file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc263b2d-31ad-4ab0-93c9-eb783bd3c36b",
   "metadata": {},
   "source": [
    "## Step 9. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "97362eb7-1c54-47c6-bfa8-e8de51e13173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging out to Tensorboard at: ./log/snn-run\n",
      "Starting training process!\n",
      "-------------------------------------\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [54]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m batch_per_gpu \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(batch_size)\n\u001b[1;32m      7\u001b[0m siamese_net\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39mtriplet_loss, optimizer\u001b[38;5;241m=\u001b[39moptimiser_obj)\n\u001b[0;32m----> 9\u001b[0m siamese_history \u001b[38;5;241m=\u001b[39m \u001b[43msiamese_net\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_per_gpu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_hard\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_per_gpu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_hard\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-------------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining complete.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/newest/lib/python3.10/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36mdata_generator\u001b[0;34m(batch_size, num_hard, split)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdata_generator\u001b[39m(batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m, num_hard\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m----> 3\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_hard_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_hard\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m         y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((batch_size, \u001b[38;5;241m3\u001b[39m\u001b[38;5;241m*\u001b[39memb_size))\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m x, y\n",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36mcreate_hard_batch\u001b[0;34m(batch_size, num_hard, split)\u001b[0m\n\u001b[1;32m     27\u001b[0m     batch_losses\u001b[38;5;241m.\u001b[39mappend(binary_distance_vectors(A_emb, P_emb)\u001b[38;5;241m-\u001b[39mbinary_distance_vectors(A_emb,P_emb))\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Sort batch_loss by distance, highest first, and keep num_hard of them\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m hard_batch_selections \u001b[38;5;241m=\u001b[39m [x \u001b[38;5;28;01mfor\u001b[39;00m _, x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_losses\u001b[49m\u001b[43m,\u001b[49m\u001b[43mhard_batches\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m     31\u001b[0m hard_batches \u001b[38;5;241m=\u001b[39m hard_batch_selections[:num_hard]\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Get batch_size - num_hard number of random examples\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "## Training:\n",
    "print(\"Logging out to Tensorboard at:\", logdir)\n",
    "print(\"Starting training process!\")\n",
    "print(\"-------------------------------------\")\n",
    "\n",
    "batch_per_gpu = int(batch_size)\n",
    "siamese_net.compile(loss=triplet_loss, optimizer=optimiser_obj)\n",
    "\n",
    "siamese_history = siamese_net.fit(\n",
    "    data_generator(batch_per_gpu, num_hard),\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks, \n",
    "    workers = 0, \n",
    "    validation_data = data_generator(batch_per_gpu, num_hard, split=\"test\"), \n",
    "    validation_steps = val_steps)\n",
    "\n",
    "print(\"-------------------------------------\")\n",
    "print(\"Training complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newest",
   "language": "python",
   "name": "newest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
