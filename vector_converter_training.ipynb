{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65b61a77-ace2-4e13-a51e-b7f87babbb45",
   "metadata": {},
   "source": [
    "# Vector Converter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc86a5b-110b-4e8a-b79e-2547ec12020a",
   "metadata": {},
   "source": [
    "## Step 1. Import needed packages\n",
    "\n",
    "Importing all the packages we need for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c607b3b6-b197-4c8e-9956-b51d99887e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Import pyplot from matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import TensorFlow & Keras \n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow.keras.backend as tf_backend \n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import Callback, CSVLogger, ModelCheckpoint\n",
    "\n",
    "# Import all other needed packages\n",
    "import numpy as np\n",
    "import csv\n",
    "from PIL import Image\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d11dd4b-850b-41b1-9376-379787551392",
   "metadata": {},
   "source": [
    "## Step 2. Generate train & test datasets\n",
    "\n",
    "Given the dataset $\\mathcal{D} = \\{ \\{\\mathbf{x}_k\\}_{k=1}^M, \\{y_k\\}_{k=1}^M \\}$ we split it into two other datasets:\n",
    "\n",
    "$$\n",
    "\\mathcal{D}_{\\text{train}} = \\{ \\{ \\mathbf{x}_k\\}_{k=1}^{\\lfloor\\eta M\\rfloor}, \\{y_k\\}_{k=1}^{\\lfloor\\eta M\\rfloor} \\} \n",
    "$$\n",
    "$$\n",
    "\\mathcal{D}_{\\text{test}} = \\{ \\{ \\mathbf{x}_k \\}_{k=\\lceil\\eta M\\rceil}^{M}, \\{y_k\\}_{k=\\lceil\\eta M\\rceil}^{M} \\}\n",
    "$$\n",
    "\n",
    "Where $\\eta = 0.8$ is a proportion we allocate for a train part of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03e546d",
   "metadata": {},
   "source": [
    "Here we simply import our $\\texttt{csv}$ file and import all the vectors into $\\texttt{feature_vector_batches_np}$, $\\texttt{feature_vector_batches_tf}$, and $\\texttt{labels}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fdaa801f-d93d-4468-a04e-1012c892576f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forming feature vectors dictionary\n",
    "feature_vectors_dictionary = {}\n",
    "\n",
    "with open('./csv_datasets/keras_facenet_feature_vectors.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    for i, row in enumerate(reader):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        \n",
    "        person_id = int(float(row[0]))\n",
    "        feature_vector = np.array(row[2:])\n",
    "        feature_vector = feature_vector.astype(np.float)\n",
    "        \n",
    "        if person_id not in feature_vectors_dictionary:\n",
    "            feature_vectors_dictionary[person_id] = [feature_vector]\n",
    "            continue\n",
    "            \n",
    "        feature_vectors_dictionary[person_id].append(feature_vector)\n",
    "\n",
    "dictionary_values = list(feature_vectors_dictionary.values()) \n",
    "        \n",
    "# Finding minimal array size\n",
    "min_array_length = int(1e10)\n",
    "for value in dictionary_values:\n",
    "    min_array_length = min(min_array_length, len(value))\n",
    "\n",
    "# Forming tensorflow and numpy arrays\n",
    "feature_vector_batches_np = []\n",
    "feature_vector_batches_tf = []\n",
    "labels = []\n",
    "\n",
    "for key in feature_vectors_dictionary:\n",
    "    value = feature_vectors_dictionary[key]\n",
    "    value_np = np.array(value[:min_array_length])\n",
    "    labels.extend([key] * min_array_length)\n",
    "    feature_vector_batches_np.extend(value_np)\n",
    "    feature_vector_batches_tf.extend(tf.convert_to_tensor(value_np))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51140ad",
   "metadata": {},
   "source": [
    "Then we shuffle $\\texttt{feature_vector_batches_np}$, $\\texttt{feature_vector_batches_tf}$, and $\\texttt{labels}$ together "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af8ccf93-2851-407b-9e42-a40b0657d47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle two lists\n",
    "temp = list(zip(feature_vector_batches_np, feature_vector_batches_tf, labels))\n",
    "random.shuffle(temp)\n",
    "temp_batches_np, temp_batches_tf, temp_labels = zip(*temp)\n",
    "feature_vector_batches_np, feature_vector_batches_tf, labels = list(temp_batches_np), list(temp_batches_tf), list(temp_labels)\n",
    "\n",
    "feature_vector_batches_tf = tf.stack(feature_vector_batches_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa2f509",
   "metadata": {},
   "source": [
    "Just to make sure our code is properly written, we define the distance function $d_f(\\mathbf{x}_1,\\mathbf{x}_2) = \\| \\mathbf{x}_1 - \\mathbf{x}_2\\|_2^2$.\n",
    "Then we take the first element in $\\texttt{feature_vector_batches_tf}$ and find $\\texttt{negative}+\\texttt{positive}$ elements in it, which basically correspond to a feature vector of different and the same person, respectively. Distance between our anchor and $\\texttt{positive}$ must be smaller than anchor and $\\texttt{negative}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c05ceac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor, Negative, and Positive labels are 119, 200, and 119\n",
      "Distance between anchor and negative is 253.54916264945064\n",
      "Distance between anchor and positive is 39.437943012123455\n"
     ]
    }
   ],
   "source": [
    "# Test shuffling\n",
    "def euclidean_distance(f1, f2):\n",
    "    return tf.reduce_sum(tf.square(f1-f2), axis=0)\n",
    "\n",
    "anchor, anchor_label = feature_vector_batches_tf[0], labels[0]\n",
    "\n",
    "positive_id, negative_id = -1, -1 \n",
    "for i, vector in enumerate(feature_vector_batches_np):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    if positive_id >= 0 and negative_id >= 0:\n",
    "        break\n",
    "    if labels[i] != anchor_label and negative_id == -1:\n",
    "        negative_id = i\n",
    "    if labels[i] == anchor_label and positive_id == -1:\n",
    "        positive_id = i\n",
    "\n",
    "negative, positive = feature_vector_batches_tf[negative_id], feature_vector_batches_tf[positive_id]\n",
    "negative_label, positive_label = labels[negative_id], labels[positive_id]\n",
    "        \n",
    "print('Anchor, Negative, and Positive labels are {}, {}, and {}'.format(anchor_label, negative_label, positive_label))\n",
    "print('Distance between anchor and negative is {}'.format(euclidean_distance(anchor, negative)))\n",
    "print('Distance between anchor and positive is {}'.format(euclidean_distance(anchor, positive)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6c8ede",
   "metadata": {},
   "source": [
    "Then divide the dataset into $X_{\\text{train}}, Y_{\\text{train}}$ - a set of train vectors and labels, and $X_{\\text{test}}, Y_{\\text{test}}$ - a set of test vectors and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c2cbe7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset length: 5512\n",
      "Length of a train dataset: 4409\n",
      "Length of a test dataset: 1103\n"
     ]
    }
   ],
   "source": [
    "# Splitting into training and test sets\n",
    "total_dataset_length = len(labels)\n",
    "test_proportion = 0.8\n",
    "train_length = int(test_proportion * total_dataset_length)\n",
    "\n",
    "X_train = feature_vector_batches_tf[:train_length]\n",
    "Y_train = labels[:train_length]\n",
    "\n",
    "X_test = feature_vector_batches_tf[train_length:]\n",
    "Y_test = labels[train_length:]\n",
    "\n",
    "num_classes = len(np.unique(Y_train))\n",
    "\n",
    "print('Total dataset length: {}'.format(total_dataset_length))\n",
    "print('Length of a train dataset: {}'.format(len(X_train)))\n",
    "print('Length of a test dataset: {}'.format(len(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847e49eb-3b65-4ab0-93bd-a2b723d981fc",
   "metadata": {},
   "source": [
    "## Step 3. Define distance function\n",
    "\n",
    "Continuous binary distance is defined as follows:\n",
    "$$\n",
    "\\hat{\\delta}(\\mathbf{x}, \\mathbf{y}) = \\frac{1}{N}\\sum_{k=1}^N |x_k - y_k|\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3524c9ce-2415-451c-b25c-13e12f524c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.25, shape=(), dtype=float32)\n",
      "tf.Tensor([0. 1. 0. 0. 1.], shape=(5,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def binary_distance(x,y):\n",
    "    return tf.reduce_mean(tf.abs(x-y),axis=0)\n",
    "\n",
    "# Check binary distance formula\n",
    "s1 = tf.constant([0.0, 0.0, 1.0, 1.0])\n",
    "s2 = tf.constant([0.0, 0.0, 1.0, 0.0])\n",
    "print(binary_distance(s1, s2))\n",
    "\n",
    "def convert_to_binary_string(x):\n",
    "    return tf.where(tf.less(x, 0.5), 0.0, 1.0)\n",
    "\n",
    "x = tf.constant([0.001, 0.98, 0.1, 0.2, 0.78])\n",
    "print(convert_to_binary_string(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dfa1d7-abb6-406a-aa8d-23e17cf3d5c0",
   "metadata": {},
   "source": [
    "## Step 4. Creating functions to create batches & triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "379b14b0-4d60-482b-a014-94714987a946",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batch(batch_size=256, split = \"train\"):\n",
    "    x_anchors = np.zeros((batch_size, 128))\n",
    "    x_positives = np.zeros((batch_size, 128))\n",
    "    x_negatives = np.zeros((batch_size, 128))\n",
    "    \n",
    "    if split == \"train\":\n",
    "        data = X_train\n",
    "        data_y = Y_train\n",
    "    elif split == \"test\":\n",
    "        data = X_test\n",
    "        data_y = Y_test\n",
    "    \n",
    "    for i in range(0, batch_size):\n",
    "        # We need to find an anchor, a positive example and a negative example\n",
    "        random_index = random.randint(0, data.shape[0] - 1)\n",
    "        x_anchor = data[random_index]\n",
    "        y = data_y[random_index]\n",
    "        \n",
    "        indices_for_pos = [index for index in data_y if index == y]\n",
    "        indices_for_neg = [index for index in data_y if index != y]\n",
    "        \n",
    "        x_positive = data[indices_for_pos[random.randint(0, len(indices_for_pos) - 1)]]\n",
    "        x_negative = data[indices_for_neg[random.randint(0, len(indices_for_neg) - 1)]]\n",
    "        \n",
    "        x_anchors[i] = x_anchor\n",
    "        x_positives[i] = x_positive\n",
    "        x_negatives[i] = x_negative\n",
    "        \n",
    "    return [x_anchors, x_positives, x_negatives]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea6c2ad5-80a5-4d47-8522-e7f9ca03abb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hard_batch(batch_size, num_hard, split=\"train\"):\n",
    "    x_anchors = np.zeros((batch_size, 128))\n",
    "    x_positives = np.zeros((batch_size, 128))\n",
    "    x_negatives = np.zeros((batch_size, 128))\n",
    "    \n",
    "    if split == \"train\":\n",
    "        data = X_train\n",
    "        data_y = Y_train\n",
    "    elif split == \"test\":\n",
    "        data = X_test\n",
    "        data_y = Y_test\n",
    "    \n",
    "    # Generate num_hard number of hard examples:\n",
    "    hard_batches = [] \n",
    "    batch_losses = []\n",
    "    rand_batches = []\n",
    "    \n",
    "    # Get some random batches\n",
    "    for i in range(0, batch_size):\n",
    "        hard_batches.append(create_batch(1, split))\n",
    "        \n",
    "        A_emb = embedding_model.predict(hard_batches[i][0])\n",
    "        P_emb = embedding_model.predict(hard_batches[i][1])\n",
    "        N_emb = embedding_model.predict(hard_batches[i][2])\n",
    "        \n",
    "        # Compute d(A, P) - d(A, N) for each selected batch\n",
    "        batch_loss = binary_distance(A_emb[0], P_emb[0]) - binary_distance(A_emb[0], N_emb[0])\n",
    "        batch_losses.append(batch_loss)\n",
    "    \n",
    "    # Sort batch_loss by distance, highest first, and keep num_hard of them\n",
    "    zipped = zip(batch_losses, hard_batches)\n",
    "    hard_batch_selections = [x for _, x in sorted(zipped, key=lambda x: x[0])]\n",
    "    hard_batches = hard_batch_selections[:num_hard]\n",
    "    \n",
    "    # Get batch_size - num_hard number of random examples\n",
    "    num_rand = batch_size - num_hard\n",
    "    for i in range(0, num_rand):\n",
    "        rand_batch = create_batch(1, split)\n",
    "        rand_batches.append(rand_batch)\n",
    "    \n",
    "    selections = hard_batches + rand_batches\n",
    "    \n",
    "    for i in range(0, len(selections)):\n",
    "        x_anchors[i] = selections[i][0]\n",
    "        x_positives[i] = selections[i][1]\n",
    "        x_negatives[i] = selections[i][2]\n",
    "        \n",
    "    return [x_anchors, x_positives, x_negatives]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b132038b-296c-48ff-8ed3-80d33c124873",
   "metadata": {},
   "source": [
    "## Step 5. Creating SNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9a605f",
   "metadata": {},
   "source": [
    "### Custom activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "94851b2e-34df-4d67-b757-210cdefff6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Model would consist of 3 dense layers of the same length as of feature vectors\n",
    "def init_embedding_model():\n",
    "    embedding_model = keras.Sequential([\n",
    "        layers.Dense(\n",
    "            20,\n",
    "            input_shape=(128,),\n",
    "            activation='relu',\n",
    "            name='input_layer',\n",
    "            kernel_initializer='he_uniform',\n",
    "            kernel_regularizer=l2(1e-3)),\n",
    "        layers.Dense(\n",
    "            128,  \n",
    "            name=\"output_layer\",\n",
    "            activation = lambda x: 1/(1+tf.math.exp(-20.0*x)))\n",
    "    ])\n",
    "    \n",
    "    embedding_model.summary()\n",
    "    return embedding_model\n",
    "\n",
    "def init_snn(embedding_model):\n",
    "    input_anchor = layers.Input(shape=(128,))\n",
    "    input_positive = layers.Input(shape=(128,))\n",
    "    input_negative = layers.Input(shape=(128,))\n",
    "\n",
    "    embedding_anchor = embedding_model(input_anchor)\n",
    "    embedding_positive = embedding_model(input_positive)\n",
    "    embedding_negative = embedding_model(input_negative)\n",
    "\n",
    "    output = layers.concatenate([embedding_anchor, embedding_positive, embedding_negative], axis=1)\n",
    "    \n",
    "    siamese_net = keras.models.Model([input_anchor, input_positive, input_negative], output)\n",
    "    siamese_net.summary()\n",
    "    \n",
    "    return siamese_net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82320c68",
   "metadata": {},
   "source": [
    "Epsilon-loss\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{\\epsilon}(\\mathbf{x}) = \\Lambda \\sum_{i=1}^{N} [\\epsilon - |x_i|]_+\n",
    "$$\n",
    "\n",
    "Max epsilon-loss error\n",
    "$$\n",
    "\\mathcal{L}_{\\epsilon}^{\\max} = \\Lambda \\cdot 3N \\epsilon\n",
    "$$\n",
    "We want\n",
    "$$\n",
    "\\mathcal{L}_{\\epsilon} \\approx 2\\Theta\n",
    "$$\n",
    "Therefore\n",
    "$$\n",
    "\\Lambda \\approx \\frac{2\\Theta}{3N\\epsilon}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e8f2dd0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.29999998, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.3\n",
    "epsilon = 0.05\n",
    "loss_amplitude = alpha/(3*128*epsilon)\n",
    "\n",
    "def epsilon_loss(x):\n",
    "    return loss_amplitude * tf.reduce_sum(tf.maximum(tf.ones((128*3,))*epsilon - tf.math.abs(x), 0))\n",
    "\n",
    "l = tf.ones(shape=(128*3,)) * (0)\n",
    "print(epsilon_loss(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5006b073-7578-4a21-abed-1a919551e014",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_loss_ratio = 0.9\n",
    "\n",
    "def combined_loss(y_true, y_pred):\n",
    "    anchor, positive, negative = y_pred[:,:128], y_pred[:,128:2*128],y_pred[:,2*128:]\n",
    "    \n",
    "    positive_distance = tf.reduce_mean(tf.math.abs(anchor - positive))\n",
    "    negative_distance = tf.reduce_mean(tf.math.abs(anchor - negative))\n",
    "    \n",
    "    distance_loss = distance_loss_ratio * tf.maximum(positive_distance - negative_distance + alpha, 0.)\n",
    "    eps_loss = (1 - distance_loss_ratio) * epsilon_loss(y_pred) \n",
    "    return distance_loss + eps_loss\n",
    "\n",
    "def triplet_loss(y_true, y_pred):\n",
    "    anchor, positive, negative = y_pred[:,:128], y_pred[:,128:2*128],y_pred[:,2*128:]\n",
    "    \n",
    "    positive_distance = tf.reduce_mean(tf.math.abs(anchor - positive))\n",
    "    negative_distance = tf.reduce_mean(tf.math.abs(anchor - negative))\n",
    "    \n",
    "    return tf.maximum(positive_distance - negative_distance + alpha, 0.)\n",
    "\n",
    "\n",
    "def epsilon_loss(y_true, y_pred):\n",
    "    anchor, positive, negative = y_pred[:,:128], y_pred[:,128:2*128],y_pred[:,2*128:]\n",
    "    return epsilon_loss(y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e18d2fe3-cb88-477e-b0d2-d3c02fc47b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(batch_size=256, num_hard=50, split=\"train\"):\n",
    "    while True:\n",
    "        x = create_hard_batch(batch_size, num_hard, split)\n",
    "        y = np.zeros((batch_size, 3*128))\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a29796-561f-44e8-b38e-50f207e30597",
   "metadata": {},
   "source": [
    "## Step 6. Setting up for training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c7fe2f3d-7cec-45ff-96de-cbefeaeee123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embedding model... \n",
      "\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (Dense)         (None, 20)                2580      \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 128)               2688      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,268\n",
      "Trainable params: 5,268\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Generating SNN... \n",
      "\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " input_5 (InputLayer)           [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " sequential_2 (Sequential)      (None, 128)          5268        ['input_4[0][0]',                \n",
      "                                                                  'input_5[0][0]',                \n",
      "                                                                  'input_6[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 384)          0           ['sequential_2[0][0]',           \n",
      "                                                                  'sequential_2[1][0]',           \n",
      "                                                                  'sequential_2[2][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5,268\n",
      "Trainable params: 5,268\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Hyperparams\n",
    "batch_size = 256\n",
    "epochs = 10\n",
    "steps_per_epoch = int(X_train.shape[0]/batch_size)\n",
    "val_steps = int(X_test.shape[0]/batch_size)\n",
    "alpha = 0.3\n",
    "num_hard = int(batch_size * 0.5) # Number of semi-hard triplet examples in the batch\n",
    "lr = 0.001\n",
    "optimiser = 'Adam'\n",
    "\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    # Create the embedding model\n",
    "    print(\"Generating embedding model... \\n\")\n",
    "    embedding_model = init_embedding_model()\n",
    "    \n",
    "    print(\"\\nGenerating SNN... \\n\")\n",
    "    # Create the SNN\n",
    "    siamese_net = init_snn(embedding_model)\n",
    "    # Compile the SNN\n",
    "    optimiser_obj = Adam(lr = lr)\n",
    "    siamese_net.compile(loss=[triplet_loss, epsilon_loss], optimizer=optimiser_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae25bdf-1a85-4c86-add0-70b7feaa0123",
   "metadata": {},
   "source": [
    "## Step 7. Testing model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eae52eae-0124-4bb9-aa37-02bc66b39c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [9.8511642e-01 7.5483108e-08 1.5013624e-03 4.2824540e-03 9.9995816e-01\n",
      " 7.1395785e-01 2.9228986e-09 1.4346215e-07 8.5831791e-02 3.2549873e-01]\n"
     ]
    }
   ],
   "source": [
    "X_test_converted = embedding_model.predict(X_test)\n",
    "\n",
    "print('Prediction:', X_test_converted[0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe2e77f4-f927-4e33-a0df-3a98cbc860f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example triplet batch:\n",
      "Distance AP: tf.Tensor(1.1315948822448263, shape=(), dtype=float64)\n",
      "Distance AN: tf.Tensor(1.2810796184203355, shape=(), dtype=float64)\n",
      "Example semi-hard triplet batch:\n",
      "Distance AP: tf.Tensor(1.14570459688548, shape=(), dtype=float64)\n",
      "Distance AN: tf.Tensor(1.0716196739231236, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "examples = create_batch(1)\n",
    "print(\"Example triplet batch:\")\n",
    "print(\"Distance AP:\", binary_distance(examples[0][0], examples[1][0]))\n",
    "print(\"Distance AN:\", binary_distance(examples[0][0], examples[2][0]))\n",
    "\n",
    "print(\"Example semi-hard triplet batch:\")\n",
    "# 1 example, containing 1 semi-hard\n",
    "ex_hard = create_hard_batch(2, 1, split=\"train\")\n",
    "print(\"Distance AP:\", binary_distance(ex_hard[0][0], ex_hard[1][0]))\n",
    "print(\"Distance AN:\", binary_distance(ex_hard[0][0], ex_hard[2][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d59eea-af69-492d-b29a-a18a9a67ed8c",
   "metadata": {},
   "source": [
    "## Step 8. Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc91d56b-4ceb-4ed3-8cce-dfda1963d304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n",
      "WARNING:tensorflow:`batch_size` is no longer needed in the `TensorBoard` Callback and will be ignored in TensorFlow 2.0.\n"
     ]
    }
   ],
   "source": [
    "# Set up logging directory\n",
    "## Use date-time as logdir name:\n",
    "#dt = datetime.now().strftime(\"%Y%m%dT%H%M\")\n",
    "#logdir = os.path.join(\"PATH/TO/LOG\",dt)\n",
    "\n",
    "## Use a custom non-dt name:\n",
    "name = \"snn-run\"\n",
    "logdir = os.path.join(\"./log\",name)\n",
    "\n",
    "if not os.path.exists(logdir):\n",
    "    os.mkdir(logdir)\n",
    "\n",
    "## Callbacks:\n",
    "# Create the TensorBoard callback\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir = logdir,\n",
    "    histogram_freq=0,\n",
    "    batch_size=batch_size,\n",
    "    write_graph=True,\n",
    "    write_grads=True, \n",
    "    write_images = True, \n",
    "    update_freq = 'epoch', \n",
    "    profile_batch=0\n",
    ")\n",
    "\n",
    "# Training logger\n",
    "csv_log = os.path.join(logdir, 'training.csv')\n",
    "csv_logger = CSVLogger(csv_log, separator=',', append=True)\n",
    "\n",
    "# Only save the best model weights based on the val_loss\n",
    "checkpoint = ModelCheckpoint(os.path.join(logdir, 'snn_model-{epoch:02d}-{val_loss:.2f}.h5'),\n",
    "                             monitor='val_loss', verbose=1,\n",
    "                             save_best_only=True, save_weights_only=True, \n",
    "                             mode='auto')\n",
    "\n",
    "# Save the embedding mode weights based on the main model's val loss\n",
    "# This is needed to reecreate the emebedding model should we wish to visualise\n",
    "# the latent space at the saved epoch\n",
    "class SaveEmbeddingModelWeights(Callback):\n",
    "    def __init__(self, filepath, monitor='val_loss', verbose=1):\n",
    "        super(Callback, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.verbose = verbose\n",
    "        self.best = np.Inf\n",
    "        self.filepath = filepath\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is None:\n",
    "            warnings.warn(\"SaveEmbeddingModelWeights requires %s available!\" % self.monitor, RuntimeWarning)\n",
    "\n",
    "        if current < self.best:\n",
    "            filepath = self.filepath.format(epoch=epoch + 1, **logs)\n",
    "            if self.verbose == 1:\n",
    "                print(\"Saving embedding model weights at %s\" % filepath)\n",
    "            embedding_model.save_weights(filepath, overwrite = True)\n",
    "            self.best = current\n",
    "            \n",
    "            # Delete the last best emb_model and snn_model\n",
    "            delete_older_model_files(filepath)\n",
    "\n",
    "# Save the embedding model weights if you save a new snn best model based on the model checkpoint above\n",
    "emb_weight_saver = SaveEmbeddingModelWeights(os.path.join(logdir, 'emb_model-{epoch:02d}.h5'))\n",
    "\n",
    "\n",
    "callbacks = [tensorboard, csv_logger, checkpoint, emb_weight_saver]\n",
    "\n",
    "\n",
    "# Save model configs to JSON\n",
    "model_json = siamese_net.to_json()\n",
    "with open(os.path.join(logdir, \"siamese_config.json\"), \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    json_file.close()\n",
    "    \n",
    "model_json = embedding_model.to_json()\n",
    "with open(os.path.join(logdir, \"embedding_config.json\"), \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    json_file.close()\n",
    "    \n",
    "\n",
    "hyperparams = {'batch_size' : batch_size,\n",
    "              'epochs' : epochs, \n",
    "               'steps_per_epoch' : steps_per_epoch, \n",
    "               'val_steps' : val_steps, \n",
    "               'alpha' : alpha, \n",
    "               'num_hard' : num_hard, \n",
    "               'optimiser' : optimiser,\n",
    "               'lr' : lr,\n",
    "               'emb_size' : 128\n",
    "              }\n",
    "\n",
    "\n",
    "with open(os.path.join(logdir, \"hyperparams.json\"), \"w\") as json_file:\n",
    "    json.dump(hyperparams, json_file)\n",
    "    \n",
    "# Set the model to TB\n",
    "tensorboard.set_model(siamese_net)\n",
    "\n",
    "def delete_older_model_files(filepath):\n",
    "    \n",
    "    model_dir = filepath.split(\"emb_model\")[0]\n",
    "    \n",
    "    # Get model files\n",
    "    model_files = os.listdir(model_dir)\n",
    "    # Get only the emb_model files\n",
    "    emb_model_files = [file for file in model_files if \"emb_model\" in file]\n",
    "    # Get the epoch nums of the emb_model_files\n",
    "    emb_model_files_epoch_nums = [file.split(\"-\")[1].split(\".h5\")[0] for file in emb_model_files]\n",
    "\n",
    "    # Find all the snn model files\n",
    "    snn_model_files = [file for file in model_files if \"snn_model\" in file]\n",
    "\n",
    "    # Sort, get highest epoch num\n",
    "    emb_model_files_epoch_nums.sort()\n",
    "    highest_epoch_num = emb_model_files_epoch_nums[-1]\n",
    "\n",
    "    # Filter the emb_model and snn_model file lists to remove the highest epoch number ones\n",
    "    emb_model_files_without_highest = [file for file in emb_model_files if highest_epoch_num not in file]\n",
    "    snn_model_files_without_highest = [file for file in snn_model_files if highest_epoch_num not in file]\n",
    "\n",
    "    # Delete the non-highest model files from the subdir\n",
    "    if len(emb_model_files_without_highest) != 0:\n",
    "        print(\"Deleting previous best model file:\", emb_model_files_without_highest)\n",
    "        for model_file_list in [emb_model_files_without_highest, snn_model_files_without_highest]:\n",
    "            for file in model_file_list:\n",
    "                os.remove(os.path.join(model_dir, file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc263b2d-31ad-4ab0-93c9-eb783bd3c36b",
   "metadata": {},
   "source": [
    "## Step 9. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97362eb7-1c54-47c6-bfa8-e8de51e13173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging out to Tensorboard at: ./log/snn-run\n",
      "Starting training process!\n",
      "-------------------------------------\n",
      "Epoch 1/18\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.2864  \n",
      "Epoch 1: val_loss improved from inf to 0.30532, saving model to ./log/snn-run/snn_model-01-0.31.h5\n",
      "Saving embedding model weights at ./log/snn-run/emb_model-01.h5\n",
      "Deleting previous best model file: ['emb_model-01.h5']\n",
      "17/17 [==============================] - 1590s 99s/step - loss: 0.2864 - val_loss: 0.3053\n",
      "Epoch 2/18\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.2575  \n",
      "Epoch 2: val_loss improved from 0.30532 to 0.28936, saving model to ./log/snn-run/snn_model-02-0.29.h5\n",
      "Saving embedding model weights at ./log/snn-run/emb_model-02.h5\n",
      "Deleting previous best model file: ['emb_model-02.h5']\n",
      "17/17 [==============================] - 1633s 97s/step - loss: 0.2575 - val_loss: 0.2894\n",
      "Epoch 3/18\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.2340  \n",
      "Epoch 3: val_loss did not improve from 0.28936\n",
      "17/17 [==============================] - 1636s 97s/step - loss: 0.2340 - val_loss: 0.2941\n",
      "Epoch 4/18\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.2050  \n",
      "Epoch 4: val_loss did not improve from 0.28936\n",
      "17/17 [==============================] - 1644s 98s/step - loss: 0.2050 - val_loss: 0.2918\n",
      "Epoch 5/18\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.1832  \n",
      "Epoch 5: val_loss improved from 0.28936 to 0.27904, saving model to ./log/snn-run/snn_model-05-0.28.h5\n",
      "Saving embedding model weights at ./log/snn-run/emb_model-05.h5\n",
      "Deleting previous best model file: ['emb_model-05.h5']\n",
      "17/17 [==============================] - 1660s 99s/step - loss: 0.1832 - val_loss: 0.2790\n",
      "Epoch 6/18\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.1559  \n",
      "Epoch 6: val_loss improved from 0.27904 to 0.26064, saving model to ./log/snn-run/snn_model-06-0.26.h5\n",
      "Saving embedding model weights at ./log/snn-run/emb_model-06.h5\n",
      "Deleting previous best model file: ['emb_model-06.h5']\n",
      "17/17 [==============================] - 1650s 98s/step - loss: 0.1559 - val_loss: 0.2606\n",
      "Epoch 7/18\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.1395  \n",
      "Epoch 7: val_loss improved from 0.26064 to 0.25623, saving model to ./log/snn-run/snn_model-07-0.26.h5\n",
      "Saving embedding model weights at ./log/snn-run/emb_model-07.h5\n",
      "Deleting previous best model file: ['emb_model-07.h5']\n",
      "17/17 [==============================] - 1658s 99s/step - loss: 0.1395 - val_loss: 0.2562\n",
      "Epoch 8/18\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.1224  \n",
      "Epoch 8: val_loss did not improve from 0.25623\n",
      "17/17 [==============================] - 1667s 99s/step - loss: 0.1224 - val_loss: 0.2577\n",
      "Epoch 9/18\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.0907  \n",
      "Epoch 9: val_loss improved from 0.25623 to 0.23826, saving model to ./log/snn-run/snn_model-09-0.24.h5\n",
      "Saving embedding model weights at ./log/snn-run/emb_model-09.h5\n",
      "Deleting previous best model file: ['emb_model-09.h5']\n",
      "17/17 [==============================] - 1678s 100s/step - loss: 0.0907 - val_loss: 0.2383\n",
      "Epoch 10/18\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.0742  \n",
      "Epoch 10: val_loss improved from 0.23826 to 0.23508, saving model to ./log/snn-run/snn_model-10-0.24.h5\n",
      "Saving embedding model weights at ./log/snn-run/emb_model-10.h5\n",
      "Deleting previous best model file: ['emb_model-10.h5']\n",
      "17/17 [==============================] - 1666s 99s/step - loss: 0.0742 - val_loss: 0.2351\n",
      "Epoch 11/18\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.0567  \n",
      "Epoch 11: val_loss improved from 0.23508 to 0.21219, saving model to ./log/snn-run/snn_model-11-0.21.h5\n",
      "Saving embedding model weights at ./log/snn-run/emb_model-11.h5\n",
      "Deleting previous best model file: ['emb_model-11.h5']\n",
      "17/17 [==============================] - 1663s 99s/step - loss: 0.0567 - val_loss: 0.2122\n",
      "Epoch 12/18\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.0421  \n",
      "Epoch 12: val_loss improved from 0.21219 to 0.20154, saving model to ./log/snn-run/snn_model-12-0.20.h5\n",
      "Saving embedding model weights at ./log/snn-run/emb_model-12.h5\n",
      "Deleting previous best model file: ['emb_model-12.h5']\n",
      "17/17 [==============================] - 1687s 100s/step - loss: 0.0421 - val_loss: 0.2015\n",
      "Epoch 13/18\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.0402  \n",
      "Epoch 13: val_loss improved from 0.20154 to 0.20028, saving model to ./log/snn-run/snn_model-13-0.20.h5\n",
      "Saving embedding model weights at ./log/snn-run/emb_model-13.h5\n",
      "Deleting previous best model file: ['emb_model-13.h5']\n",
      "17/17 [==============================] - 1699s 101s/step - loss: 0.0402 - val_loss: 0.2003\n",
      "Epoch 14/18\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.0356  \n",
      "Epoch 14: val_loss improved from 0.20028 to 0.18308, saving model to ./log/snn-run/snn_model-14-0.18.h5\n",
      "Saving embedding model weights at ./log/snn-run/emb_model-14.h5\n",
      "Deleting previous best model file: ['emb_model-14.h5']\n",
      "17/17 [==============================] - 1694s 101s/step - loss: 0.0356 - val_loss: 0.1831\n",
      "Epoch 15/18\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.0301  \n",
      "Epoch 15: val_loss did not improve from 0.18308\n",
      "17/17 [==============================] - 1669s 99s/step - loss: 0.0301 - val_loss: 0.1881\n",
      "Epoch 16/18\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.0283  \n",
      "Epoch 16: val_loss did not improve from 0.18308\n",
      "17/17 [==============================] - 1702s 101s/step - loss: 0.0283 - val_loss: 0.1850\n",
      "Epoch 17/18\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.0274  \n",
      "Epoch 17: val_loss did not improve from 0.18308\n",
      "17/17 [==============================] - 1707s 101s/step - loss: 0.0274 - val_loss: 0.1962\n",
      "Epoch 18/18\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.0276  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-31 10:54:50.546970: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18: val_loss did not improve from 0.18308\n",
      "17/17 [==============================] - 1710s 102s/step - loss: 0.0276 - val_loss: 0.1920\n",
      "-------------------------------------\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "## Training:\n",
    "print(\"Logging out to Tensorboard at:\", logdir)\n",
    "print(\"Starting training process!\")\n",
    "print(\"-------------------------------------\")\n",
    "\n",
    "siamese_net.compile(loss=triplet_loss, optimizer=optimiser_obj)\n",
    "\n",
    "siamese_history = siamese_net.fit(\n",
    "    data_generator(int(batch_size), num_hard),\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=18,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks, \n",
    "    workers = 0, \n",
    "    validation_data = data_generator(int(batch_size), num_hard, split=\"test\"), \n",
    "    validation_steps = val_steps)\n",
    "\n",
    "print(\"-------------------------------------\")\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f62d4a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "font = {'family' : 'serif',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 16}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "figure(figsize=(10, 8))\n",
    "plt.plot(siamese_history.history['loss'], color='red')\n",
    "plt.plot(siamese_history.history['val_loss'], color='blue')\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d02fcfc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (Dense)         (None, 20)                2580      \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 128)               2688      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,268\n",
      "Trainable params: 5,268\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def json_to_dict(json_src):\n",
    "    with open(json_src, 'r') as j:\n",
    "        return json.loads(j.read())\n",
    "      \n",
    "## Load in best trained SNN and emb model\n",
    "\n",
    "# The best performing model weights has the higher epoch number due to only saving the best weights\n",
    "highest_epoch = 0\n",
    "dir_list = os.listdir(logdir)\n",
    "\n",
    "for file in dir_list:\n",
    "    if file.endswith(\".h5\"):\n",
    "        epoch_num = int(file.split(\"-\")[1].split(\".h5\")[0])\n",
    "        if epoch_num > highest_epoch:\n",
    "            highest_epoch = epoch_num\n",
    "\n",
    "# Find the embedding and SNN weights src for the highest_epoch (best) model\n",
    "for file in dir_list:\n",
    "    # Zfill ensure a leading 0 on number < 10\n",
    "    if (\"-\" + str(highest_epoch).zfill(2)) in file:\n",
    "        if file.startswith(\"emb\"):\n",
    "            embedding_weights_src = os.path.join(logdir, file)\n",
    "        elif file.startswith(\"snn\"):\n",
    "            snn_weights_src = os.path.join(logdir, file)\n",
    "\n",
    "hyperparams = os.path.join(logdir, \"hyperparams.json\")\n",
    "snn_config = os.path.join(logdir, \"siamese_config.json\")\n",
    "emb_config = os.path.join(logdir, \"embedding_config.json\")\n",
    "\n",
    "snn_config = json_to_dict(snn_config)\n",
    "emb_config = json_to_dict(emb_config)\n",
    "\n",
    "# json.dumps to make the dict a string, as required by model_from_json\n",
    "loaded_emb_model = init_embedding_model()\n",
    "loaded_emb_model.load_weights(embedding_weights_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a12a544-f9de-4ba5-a994-b7708352055d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same similarity tf.Tensor(0.7669841, shape=(), dtype=float32)\n",
      "Diff similarity tf.Tensor(0.61573076, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "X_test_predicted = embedding_model.predict(X_test)\n",
    "\n",
    "same_sim, num_same = 0, 0\n",
    "classes = np.unique(Y_test)\n",
    "\n",
    "for c in classes:\n",
    "    X_to_test = [convert_to_binary_string(x) for i,x in enumerate(X_test_predicted) if Y_test[i] == c]\n",
    "    for i in range(len(X_to_test)-1):\n",
    "        dist = binary_distance(X_to_test[i], X_to_test[i+1])\n",
    "        same_sim += (1 - dist)\n",
    "        num_same += 1\n",
    "\n",
    "diff_sim, num_diff = 0, 0\n",
    "for i in range(len(classes)-1):\n",
    "    X1 = [convert_to_binary_string(x) for k,x in enumerate(X_test_predicted) if Y_test[k] == classes[i]]\n",
    "    X2 = [convert_to_binary_string(x) for k,x in enumerate(X_test_predicted) if Y_test[k] == classes[i+1]]\n",
    "    for j in range(min(len(X1),len(X2))):\n",
    "        dist = binary_distance(X1[j], X2[j])\n",
    "        diff_sim += (1 - dist)\n",
    "        num_diff += 1\n",
    "\n",
    "print('Same similarity', same_sim/num_same)\n",
    "print('Diff similarity', diff_sim/num_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "370be4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same similarity tf.Tensor(0.76985127, shape=(), dtype=float32)\n",
      "Diff similarity tf.Tensor(0.58202666, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "avg_same_sim, num_sim = 0, 0\n",
    "classes = np.unique(Y_test)\n",
    "\n",
    "for c in classes:\n",
    "    X_to_test = [convert_to_binary_string(x) for i,x in enumerate(X_test) if Y_test[i] == c]\n",
    "    for i in range(len(X_to_test)-1):\n",
    "        dist = binary_distance(X_to_test[i], X_to_test[i+1])\n",
    "        avg_same_sim += (1 - dist)\n",
    "        num_sim += 1\n",
    "\n",
    "avg_diff_sim, num_diff = 0, 0\n",
    "for i in range(len(classes)-1):\n",
    "    X1 = [convert_to_binary_string(x) for k,x in enumerate(X_test) if Y_test[k] == classes[i]]\n",
    "    X2 = [convert_to_binary_string(x) for k,x in enumerate(X_test) if Y_test[k] == classes[i+1]]\n",
    "    for j in range(min(len(X1),len(X2))):\n",
    "        dist = binary_distance(X1[j], X2[j])\n",
    "        avg_diff_sim += (1 - dist)\n",
    "        num_diff += 1\n",
    "\n",
    "print('Same similarity', avg_same_sim/num_sim)\n",
    "print('Diff similarity', avg_diff_sim/num_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072adcf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newest",
   "language": "python",
   "name": "newest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
